import{U as g,A as w,F as i}from"./index-BwDKQVXi.js";import{G}from"./GPUMipmaps-Sf4roZHW.js";import{v as L,m as s}from"./wgpu-matrix.module-BCZfl02X.js";import{C as _}from"./Color-DRvW8-9j.js";import{Q as k}from"./Quad-VFYOTGYq.js";const q=""+new URL("retriever-EycY0dhu.webm",import.meta.url).href;/**
 * @module Loading Video
 * @author Ustym Ukhman <ustym.ukhman@gmail.com>
 * @description This lesson is reproduced from WebGPU Loading Images into Textures
 * {@link https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html#loading-video}&nbsp;
 * and developed by using a version listed below. Please note that this code
 * may be simplified in future thanks to more recent library APIs.
 * @version 0.0.5
 * @license MIT
 */(async function(u){let t;try{t=new(await g.RenderPipeline(u,"Loading Video"))}catch(e){alert(e)}const b=0,p=[],E=1,T=2e3,h=[0,1,0],B=[0,0,0],A=Math.PI*60/180,N=[0,0,2],R=L.set(1.2,.7),l=s.perspective(A,t.AspectRatio,E,T),C=s.inverse(s.lookAt(N,B,h)),F=s.multiply(l,C),r=document.createElement("video");r.muted=r.loop=!0,r.preload="auto",r.src=q;const c=new(await g.Texture());c.SetRenderer(t);let m=!1;await x(r);const P=v(r,!0),S=!("requestVideoFrameCallback"in r);t.CreatePipeline({module:t.CreateShaderModule([k,G])});const y=t.CreateColorAttachment();if(y.clearValue=new _(5000268).rgba,t.CreatePassDescriptor(y),!S){const e=()=>{r.requestVideoFrameCallback(e),m=!0};r.requestVideoFrameCallback(e)}for(let e=0;e<8;e++){const o=c.CreateSampler({addressModeU:w.REPEAT,addressModeV:w.REPEAT,magFilter:e&1?i.LINEAR:i.NEAREST,minFilter:e&2?i.LINEAR:i.NEAREST,mipmapFilter:e&4?i.LINEAR:i.NEAREST}),n=16*Float32Array.BYTES_PER_ELEMENT,a=t.CreateBuffer({usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST,size:n}),d=new Float32Array(n/Float32Array.BYTES_PER_ELEMENT),f=d.subarray(b,16);t.AddBindGroups(t.CreateBindGroup(t.CreateBindGroupEntries([o,P.createView(),{buffer:a}]))),p.push({matrixBuffer:a,matrixValues:d,matrix:f})}function v(e,o=!1){return c.CopyImageToTexture(e,{create:{usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST,format:"rgba8unorm",mipmaps:o}})}function x(e){return new Promise((o,n)=>{if(e.addEventListener("error",n),"requestVideoFrameCallback"in e)e.requestVideoFrameCallback(o);else{const a=()=>e.currentTime?o():requestAnimationFrame(a);a()}e.play().catch(n)})}function U(){requestAnimationFrame(U),(S||m)&&(c.CopyImageToTexture(r,{texture:P}),m=!1),p.forEach(({matrix:e,matrixBuffer:o,matrixValues:n},a)=>{const f=a%4-1.5,I=+(a<4)*2-1,M=[f*R[0],I*R[1],-50*.5];s.translate(F,M,e),s.rotateX(e,Math.PI*.5,e),s.scale(e,[1,50*2,1],e),s.translate(e,[-.5,-.5,0],e),t.WriteBuffer(o,n),t.SetActiveBindGroups(a),t.Render(6,!1)}),t.Submit()}const V=new ResizeObserver(e=>{for(const o of e){const{inlineSize:n,blockSize:a}=o.contentBoxSize[0];t.SetCanvasSize(n,a)}s.perspective(A,t.AspectRatio,E,T,l),s.multiply(l,C,F),requestAnimationFrame(U)});u.addEventListener("click",()=>r[r.paused?"play":"pause"]()),V.observe(u)})(document.getElementById("lesson"));
