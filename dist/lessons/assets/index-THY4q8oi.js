import{M as G}from"./MipmapFilter-nkAaR1eK.js";import{D as g,v as L,a as n,C as _,F as i,A as w}from"./index-Dm8t6IxS.js";import{Q as D}from"./Quad-VFYOTGYq.js";const k=""+new URL("retriever-EycY0dhu.webm",import.meta.url).href;/**
 * @module Loading Video
 * @author Ustym Ukhman <ustym.ukhman@gmail.com>
 * @description This lesson is reproduced from WebGPU Loading Images into Textures
 * {@link https://webgpufundamentals.org/webgpu/lessons/webgpu-importing-textures.html#loading-video}&nbsp;
 * and developed by using a version listed below. Please note that this code
 * may be simplified in future thanks to more recent library APIs.
 * @version 0.0.5
 * @license MIT
 */(async function(f){let t;try{t=new(await g.RenderPipeline(f,"Loading Video"))}catch(e){alert(e)}const v=0,p=[],E=1,T=2e3,h=[0,1,0],B=[0,0,0],A=Math.PI*60/180,N=[0,0,2],R=L.set(1.2,.7),u=n.perspective(A,t.AspectRatio,E,T),C=n.inverse(n.lookAt(N,B,h)),F=n.multiply(u,C),r=document.createElement("video");r.muted=r.loop=!0,r.preload="auto",r.src=k;const c=new(await g.Texture());c.SetRenderer(t);let l=!1;await x(r);const S=U(r,!0),P=!("requestVideoFrameCallback"in r);t.CreatePipeline({module:t.CreateShaderModule([D,G])});const y=t.CreateColorAttachment();if(y.clearValue=new _(5000268).rgba,t.CreatePassDescriptor(y),!P){const e=()=>{r.requestVideoFrameCallback(e),l=!0};r.requestVideoFrameCallback(e)}for(let e=0;e<8;e++){const o=c.CreateSampler({addressModeU:w.REPEAT,addressModeV:w.REPEAT,magFilter:e&1?i.LINEAR:i.NEAREST,minFilter:e&2?i.LINEAR:i.NEAREST,mipmapFilter:e&4?i.LINEAR:i.NEAREST}),s=16*Float32Array.BYTES_PER_ELEMENT,a=t.CreateBuffer({usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST,size:s}),d=new Float32Array(s/Float32Array.BYTES_PER_ELEMENT),m=d.subarray(v,16);t.AddBindGroups(t.CreateBindGroup(t.CreateBindGroupEntries([o,S.createView(),{buffer:a}]))),p.push({matrixBuffer:a,matrixValues:d,matrix:m})}function U(e,o=!1){return c.CopyImageToTexture(e,{create:{usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST,format:"rgba8unorm",mipmaps:o}})}function x(e){return new Promise((o,s)=>{if(e.addEventListener("error",s),"requestVideoFrameCallback"in e)e.requestVideoFrameCallback(o);else{const a=()=>e.currentTime?o():requestAnimationFrame(a);a()}e.play().catch(s)})}function b(){requestAnimationFrame(b),(P||l)&&(c.CopyImageToTexture(r,{texture:S}),l=!1),p.forEach(({matrix:e,matrixBuffer:o,matrixValues:s},a)=>{const m=a%4-1.5,V=+(a<4)*2-1,I=[m*R[0],V*R[1],-50*.5];n.translate(F,I,e),n.rotateX(e,Math.PI*.5,e),n.scale(e,[1,50*2,1],e),n.translate(e,[-.5,-.5,0],e),t.WriteBuffer(o,s),t.SetActiveBindGroups(a),t.Render(6,!1)}),t.Submit()}const M=new ResizeObserver(e=>{for(const o of e){const{inlineSize:s,blockSize:a}=o.contentBoxSize[0];t.SetCanvasSize(s,a)}n.perspective(A,t.AspectRatio,E,T,u),n.multiply(u,C,F),requestAnimationFrame(b)});f.addEventListener("click",()=>r[r.paused?"play":"pause"]()),M.observe(document.body)})(document.getElementById("lesson"));
