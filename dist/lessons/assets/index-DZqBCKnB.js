import{D as b,v as M,a as n,C as _,A as I,F as c}from"./index-sDmynApN.js";import{Q as L}from"./Quad-VFYOTGYq.js";const U=""+new URL("pomeranian-BxXy5_gQ.mp4",import.meta.url).href;var z="struct Transform{matrix: mat4x4f};struct VertexOutput{@builtin(position)position: vec4f,@location(0)textureCoord: vec2f};@group(0)@binding(0)var Sampler: sampler;@group(0)@binding(1)var Texture: texture_external;@group(0)@binding(2)var<uniform>transform: Transform;@vertex fn vertex(@builtin(vertex_index)index: u32)->VertexOutput {var output: VertexOutput;var position=GetQuadCoord(index);position=(position+1)*0.5;output.position=transform.matrix*vec4f(position,0.0,1.0);output.textureCoord=position;return output;}@fragment fn fragment(@location(0)textureCoord: vec2f)->@location(0)vec4f {return textureSampleBaseClampToEdge(Texture,Sampler,textureCoord);}";/**
 * @module Using Video
 * @author Ustym Ukhman <ustym.ukhman@gmail.com>
 * @description This lesson is reproduced from WebGPU Using Video Efficiently
 * {@link https://webgpufundamentals.org/webgpu/lessons/webgpu-textures-external-video.html}&nbsp;
 * and developed by using a version listed below. Please note that this code
 * may be simplified in future thanks to more recent library APIs.
 * @version 0.0.6
 * @license MIT
 */(async function(p){let t;try{t=new(await b.RenderPipeline(p,"Using Video"))}catch(e){alert(e)}const y=0,m=[],d=1,f=2e3,R=[0,1,0],P=[0,0,0],x=Math.PI*60/180,B=[0,0,2],E=M.set(1.2,.5),l=n.perspective(x,t.AspectRatio,d,f),v=n.lookAt(B,P,R),g=n.multiply(l,v),i=document.createElement("video");i.muted=i.loop=!0,i.preload="auto",i.src=U,t.CreatePipeline({module:t.CreateShaderModule([L,z])});const C=t.CreateColorAttachment();C.clearValue=new _(5000268).rgba,t.CreatePassDescriptor(C);const S=new(await b.LegacyTexture());await F(i);for(let e=0;e<4;e++){const r=S.CreateSampler({magFilter:e&1?c.LINEAR:c.NEAREST,minFilter:e&2?c.LINEAR:c.NEAREST,addressModeUV:I.REPEAT}),o=16*Float32Array.BYTES_PER_ELEMENT,a=t.CreateBuffer({usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST,size:o}),s=new Float32Array(o/Float32Array.BYTES_PER_ELEMENT),u=s.subarray(y,16);m.push({sampler:r,matrixBuffer:a,matrixValues:s,matrix:u})}function F(e){return new Promise((r,o)=>{if(e.addEventListener("error",o),"requestVideoFrameCallback"in e)e.requestVideoFrameCallback(r);else{const a=()=>e.currentTime?r():requestAnimationFrame(a);a()}e.play().catch(o)})}function A(){requestAnimationFrame(A);const e=S.ImportExternalTexture(i);m.forEach(({matrix:r,sampler:o,matrixBuffer:a,matrixValues:s},u)=>{const w=u%2-.5,T=+(u<2)*2-1,V=[w*E[0],T*E[1],-.5];n.translate(g,V,r),n.rotateX(r,Math.PI*.25*Math.sign(T),r),n.scale(r,[1,-1,1],r),n.translate(r,[-.5,-.5,0],r),t.WriteBuffer(a,s),t.SetBindGroups(t.CreateBindGroup(t.CreateBindGroupEntries([o,e,{buffer:a}]))),t.Render(6,!1)}),t.Submit()}const h=new ResizeObserver(e=>{for(const r of e){const{inlineSize:o,blockSize:a}=r.contentBoxSize[0];t.SetCanvasSize(o,a)}n.perspective(x,t.AspectRatio,d,f,l),n.multiply(l,v,g),requestAnimationFrame(A)});p.addEventListener("click",()=>i[i.paused?"play":"pause"]()),h.observe(document.body)})(document.getElementById("lesson"));
